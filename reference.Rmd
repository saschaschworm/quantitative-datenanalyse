---
title: "Kurzreferenz zur quantitativen Datenanalyse"
description: |
  Diese Kurzreferenz listet kompakt all jene Formeln auf, die während der Vorlesungen zur Berechnung deskriptiver und inferentieller Maße verwendet wurden. Darüber hinaus sind entsprechende Rechenwege zur händischen Bestimmung dieser Maße exemplarisch anhand eines Datensatzes dargestellt; ebenso wie die korrespondierenden R-Befehle.
author:
  - name: "Sascha Schworm"
    url: https://www.saschaschworm.de
    affiliation: Bergische Universität Wuppertal
    affiliation_url: https://www.uni-wuppertal.de
date: December 7, 2021
citation_url: https://saschaschworm.github.io/quantitative-datenanalyse/reference.html
bibliography: bibliography.bib
link-citations: true
lang: de
site: distill::distill_website
---

```{r initialization, include = FALSE}
base::options(scipen=999)
base::set.seed(1909)

knitr::opts_chunk$set(echo = TRUE)

library(mosaic)
library(gridExtra)
library(hrbrthemes)
```

## Datensatz

Falls nicht abweichend angegeben, bezieht sich ein Großteil der Berechnungen dieser Kurzreferenz auf den in Tabelle \@ref(tab:dataset) dargestellten Übungsdatensatz. Dieser ist Ergebnis einer Befragung von fünf Studierenden während einer Statistikvorlesung im Sommersemester 2018 und beinhaltet die zurückgelegten Anfahrtskilometer zum Hochschulzentrum Düsseldorf $(x)$ und die dafür benötigte Zeit in Minuten $(y)$.

```{r dataset, echo = FALSE}
data.drive <- data.frame(x = c(2, 6, 8, 10, 12), y = c(12, 20, 20, 30, 32))
knitr::kable(data.drive, row.names = TRUE, booktabs = TRUE, escape = FALSE, caption = "Inhalt des Übungsdatensatzes, wobei $x$ die zurückgelegten Anfahrtskilometer zum Hochschulzentrum Düsseldorf und $y$ die dafür benötigte Zeit in Minuten bezeichnen.")
```

Um die Beispielberechnungen in `R` replizieren zu können, führen Sie bitte das folgende Codefragment in der Konsole Ihrer `R`-Umgebung  aus.

```{r, eval = FALSE}
data.drive <- data.frame(x = c(2, 6, 8, 10, 12), y = c(12, 20, 20, 30, 32))
```

Die Konstruktion von Hilfstabellen erleichtert die händische Berechnung von statistischen Kennzahlen. In Tabelle \@ref(tab:auxiliary-table-1) ist eine Variante eine solcher Hilfstabelle dargestellt. Nachteil dieser Hilfstabelle ist allerdings die zeitaufwendige und fehleranfällige Konstruktion.

```{r auxiliary-table-1, echo = FALSE}
table.h1 <- data.frame(data.drive$x, data.drive$y, data.drive$x - mean(data.drive$x), data.drive$y - mean(data.drive$y), (data.drive$x - mean(data.drive$x)) ** 2, (data.drive$y - mean(data.drive$y)) ** 2, (data.drive$x - mean(data.drive$x)) * (data.drive$y - mean(data.drive$y)))
table.h1[nrow(table.h1) + 1,] <- colSums(table.h1)
rownames(table.h1) <- c(1:5, "$\\sum$")
colnames(table.h1) <- c("$x_i$", "$y_i$", "$x_i - \\bar x$", "$y_i - \\bar y$", "$(x_i - \\bar x)^2$", "$(y_i - \\bar y)^2$", "$(x_i - \\bar x)(y_i - \\bar y)$")
knitr::kable(table.h1, row.names = TRUE, booktabs = TRUE, escape = FALSE, caption = "Basishilfstabelle zur Berechnung statistischer Kennzahlen in Bezug auf den Übungsdatensatz.")
```

Durch Anwendung eines mathematischen Kniffs (Verschiebungssatz) bei der Berechnung von Varianzen und Kovarianzen genügt jedoch eine kompaktere Hilfstabelle, wie sie in Tabelle \@ref(tab:auxiliary-table-2) dargestellt ist. Diese lässt sich deutlich schneller, einfacher und bei geringem Umfang sogar ohne Taschenrechner konstruieren. Daher wird die Anwendung des Verschiebungssatzes dringend empfohlen und im Folgenden - wann immer möglich - exemplarisch dargestellt. Insbesondere während der Klausur lässt sich somit viel Zeit sparen und reduziert unnötige Fehler.

```{r auxiliary-table-2, echo = FALSE}
table.h2 <- data.frame(data.drive$x, data.drive$y, data.drive$x ** 2, data.drive$y ** 2, data.drive$x * data.drive$y)
table.h2[nrow(table.h2) + 1,] <- colSums(table.h2)
rownames(table.h2) <- c(1:5, "$\\sum$")
colnames(table.h2) <- c("$x_i$", "$y_i$", "$x_i^2$", "$y_i^2$", "$x_iy_i$")
knitr::kable(table.h2, row.names = TRUE, booktabs = TRUE, escape = FALSE, caption = "Vereinfachte Hilfstabelle zur Berechnung statistischer Kennzahlen in Bezug auf den Übungsdatensatz bei Anwendung des Verschiebungssatzes nach Steiner.")
```

## Lagemaße

### Arithmetischer Mittelwert

Der arithmetische Mittelwert $\bar x$ ist die Merkmalssumme der Merkmalsausprägungen $x_i, \dots, x_n$ geteilt durch die Anzahl der Merkmalsträger $n$, d.h.

$$\begin{equation} 
  \bar x = \frac{1}{n} \sum_{i = 1}^n x_i.
(\#eq:mean)\end{equation}$$

#### Berechnung per Hand

$$\bar x = \frac{38}{5} = 7.6 \qquad \bar y = \frac{114}{5} = 22.8$$

#### Berechnung mit R

```{r}
mean(data.drive$x)
mean(data.drive$y)
```

### Median

Der Median $\tilde{x}_{0.5}$ ist für ungerades $n$ die mittlere Beobachtung und für gerades $n$ das arithmetische Mittel der beiden in der Mitte liegenden Beobachtungen der geordneten Urliste $x_{(0)} \le \dots \le x_{(n)}$, d.h.

$$\begin{equation}
  \tilde{x}_{0.5} =
  \begin{cases}
    \frac{1}{2} (x_{\left(\frac{n}{2}\right)} + x_{\left(\frac{n}{2} + 1\right)}), & \text{wenn }n \text{ gerade,} \\
    x_{\left(\frac{n + 1}{2}\right)}, & \text{wenn }n \text{ ungerade.}
  \end{cases}
(\#eq:median)\end{equation}$$

#### Berechnung per Hand

$$\tilde{x}_{0.5} = x_{\left(\frac{5 + 1}{2}\right)} = x_{(3)} = 8 \qquad \tilde{y}_{0.5} = y_{\left(\frac{5 + 1}{2}\right)} = y_{(3)} = 20$$

#### Berechnung mit R

```{r}
median(data.drive$x)
median(data.drive$y)
```

### Quantil

Das Quantil $\tilde{x}_p$ mit $0 < p < 1$ ist der Wert, für den mindestens ein Anteil $p$ der der geordneten Urliste $x_{(0)} \le \dots \le x_{(n)}$ kleiner/gleich $\tilde{x}_p$ und mindestens ein Anteil $1 - p$ größer/gleich $\tilde{x}_p$ ist, d.h.

$$\begin{equation}
  \tilde{x}_p =
  \begin{cases}
    \frac{1}{2} (x_{(np)} + x_{(np + 1)}), & \text{wenn } np \text{ ganzzahlig,} \\
    x_{(\lfloor np + 1 \rfloor)}, & \text{wenn } np \text{ nicht ganzzahlig,}
  \end{cases}
(\#eq:quantiles)\end{equation}$$
  
wobei $\lfloor a \rfloor$ die größte ganze Zahl ist, die kleiner oder gleich $a$ ist. Für ganzzahliges $np$ ist die Formel nur approximativ für den tatsächlichen Wert des Quantils.

#### Berechnung per Hand

$$\begin{matrix}
\tilde{x}_{0.25} =  x_{(\lfloor 5 \cdot 0.25 + 1 \rfloor)} = x_{(2)} = 6 & \tilde{x}_{0.75} =  x_{(\lfloor 5 \cdot 0.75 + 1 \rfloor)} = x_{(4)} = 10 \\[1em]
\tilde{y}_{0.25} =  y_{(\lfloor 5 \cdot 0.25 + 1 \rfloor)} = y_{(2)} = 20 & \tilde{y}_{0.75} =  y_{(\lfloor 5 \cdot 0.75 + 1 \rfloor)} = y_{(4)} = 30
\end{matrix}$$

$$\begin{matrix}
\tilde{x}_{0.8} = \frac{1}{2} (x_{(5 \cdot 0.8)} + x_{(5 \cdot 0.8 + 1)}) = \frac{1}{2} (x_{(4)} + x_{(5)}) = \frac{10 + 12}{2} = 11 \\[1em]
\tilde{y}_{0.8} = \frac{1}{2} (y_{(5 \cdot 0.8)} + y_{(5 \cdot 0.8 + 1)}) =  \frac{1}{2} (y_{(4)} + x_{(5)}) = \frac{30 + 32}{2} = 31
\end{matrix}$$

#### Berechnung mit R

```{r}
quantile(data.drive$x, probs = c(0.25, 0.75, 0.8))
quantile(data.drive$y, probs = c(0.25, 0.75, 0.8))
```

## Streuungsmaße

### Varianz

Die Stichprobenvarianz $s_x^2$ ist die Summe der quadratischen Abweichung der Merkmalsausprägungen $x_i, \dots, x_n$ von ihrem Mittelwert $\bar x$ geteilt durch die Anzahl der Freiheitsgrade $n - 1$, wobei $n$ die Anzahl der Merkmalsträger ist, d.h.

$$\begin{equation}
  s_x^2 = \frac{1}{n - 1} \sum_{i = 1}^n (x_i - \bar x)^2.
(\#eq:var1)\end{equation}$$
  
Durch die Anwendung des Verschiebungssatzes auf die Grundformel ergibt sich

$$\begin{equation}
  s_x^2 = \frac{1}{n -1} \left(\sum_{i = 1}^n x_i^2 - n \bar x^2 \right).
(\#eq:var2)\end{equation}$$

#### Berechnung per Hand

$$\begin{align*}
s_x^2 & = \frac{59.2}{5 - 1} = 14.8  && s_y^2 = \frac{268.8}{5 - 1} = 67.2 \\[1em]
s_x^2 & = \frac{348 - 5 \cdot 7.6^2}{5 - 1} = \frac{59.2}{4} = 14.8 && s_y^2 = \frac{2868 - 5 \cdot 22.8^2}{5 - 1} = \frac{268.8}{4} = 67.2
\end{align*}$$

#### Berechnung mit R

```{r}
var(data.drive$x)
var(data.drive$y)
```

### Standardabweichung

Die Stichprobenstandardabweichung $s_x$ ist die positive Wurzel aus der Stichprobenvarianz $s_x^2$, d.h.

$$\begin{equation}
  s_x = \sqrt{s_x^2}.
(\#eq:std)\end{equation}$$

#### Berechnung per Hand

$$s_x = \sqrt{14.8} = 3.8471 \qquad s_y = \sqrt{67.2} = 8.1976$$

#### Berechnung mit R

```{r}
sd(data.drive$x)
sd(data.drive$y)
```

### Interquartilsabstand

Der Interquartilsabstand $d_{Q_x}$ ist die Differenz zwischem dem oberen Quantil $\tilde{x}_{0.75}$ und dem unteren Quantil $\tilde{x}_{0.25}$, d.h.

$$\begin{equation}
  d_{Q_x} = \tilde{x}_{0.75} - \tilde{x}_{0.25}.
(\#eq:iqr)\end{equation}$$

#### Berechnung per Hand

$$d_{Q_x} = 10 - 6 = 4 \qquad d_{Q_y} = 30 - 20 = 10$$

#### Berechnung mit R

```{r}
iqr(data.drive$x)
iqr(data.drive$y)
```

## Zusammenhangsmaße

### Kovarianz
  
Die Kovarianz $s_{xy}$ ist die Summe der Abweichung der Merkmalsausprägungen $x_i, \dots, x_n$ von ihrem Mittelwert $\bar x$ multipliziert mit der Abweichung der Merkmalsausprägungen $y_i, \dots, y_n$ von ihrem Mittelwert $\bar y$ geteilt durch die Anzahl der Freiheitsgrade $n - 1$, wobei $n$ die Anzahl der Merkmalsträger ist, d.h.

$$\begin{equation}
  s_{xy} = \frac{1}{n - 1} \sum_{i = 1}^n (x_i - \bar x)(y_i - \bar x)
(\#eq:cov1)\end{equation}$$

Durch die Anwendung des Verschiebungssatzes auf die Grundformel ergibt sich

$$\begin{equation}
  s_{xy} = \frac{1}{n - 1} \left(\sum_{i = 1}^n x_i y_i - n \bar x \bar y\right).
(\#eq:cov2)\end{equation}$$

#### Berechnung per Hand

$$s_{xy} = \frac{121.6}{5 - 1} = 30.4 \qquad s_{xy} = \frac{988 - 5 \cdot 7.6 \cdot 22.8}{4} = \frac{121.6}{4} = 30.4$$

#### Berechnung mit R

```{r}
cov(y ~ x, data = data.drive)
```

### Korrelationskoeffizient

Die Standardisierung der Kovarianz $s_{xy}$ ergibt den Bravais-Pearson-Korrelationskoeffizient $r_{xy}$, welcher der Quotient aus der Kovarianz $s_{xy}$ und dem Produkt der Standardabweichungen von $x$ und $y$ ist, d.h.

$$\begin{equation}
  r_{xy} = \frac{s_{xy}}{s_x \cdot s_y}.
(\#eq:cor)\end{equation}$$

#### Berechnung per Hand

$$r_{xy} = \frac{30.4}{3.8471 \cdot 8.1976} = 0.9639$$

#### Berechnung mit R

```{r}
cor(y ~ x, data = data.drive)
```

## Normalverteilung

### Standardisierung/Z-Transformation

Subtrahiert man von einer normalverteilten Zufallsvariable $X$ den Erwartungswert $\mu$ und teilt das Ergebnis durch die Standardabweichung $\sigma$, so folgt diese Zufallsvariable einer Standardnormalverteilung mit $\mu = 0$ und $\sigma = 1$, d.h.

$$\begin{equation}
  Z = \frac{X - \mu}{\sigma} \sim N(0, 1).
(\#eq:standardization1)\end{equation}$$
      
Da die Eigenschaften der zugrundeliegenden Verteilung der Zufallsvariablen häufig nicht bekannt sind, wird statt des Erwartungswerts und der Standardabweichung das arithmetische Mittel $\bar x$ und die empirische Standardabweichung $s_x$ verwendet. Die Standardisierung eines Merkmals aus einem Datensatz erfolgt also über 
    
$$\begin{equation}
  z_i = \frac{x_i - \bar x}{s_x} \quad \forall x \in \{x_1, \dots, x_n\}.
(\#eq:standardization2)\end{equation}$$

#### Berechnung per Hand

Im Folgenden wird angenommen, dass das Merkmal *Anfahrtskilometer zum Hochschulzentrum* einer Normalverteilung mit unbekannten Parametern folgt. Aus den vorherigen Kapiteln ist bekannt, dass $\bar x = 7.6$ und $s_x = 3.8471$ ist. Somit ergibt die Standardisierung des Merkmals die nachfolgenden Werte:

$$\begin{align}
z_1 & = \frac{2 - 7.6}{3.8471} = -1.4557 & z_2 & = \frac{6 - 7.6}{3.8471} = -0.4159 \\
z_3 & = \frac{8 - 7.6}{3.8471} = 0.1040 & z_4 & = \frac{10 - 7.6}{3.8471} = 0.6239 \\
z_5 & = \frac{12 - 7.6}{3.8471} = 1.1437
\end{align}$$

#### Berechnung mit R

```{r}
zscore(data.drive$x)
```

### Verteilungsfunktion

Die Verteilungsfunktion $F(x)$ der Normalverteilung ist definiert als das Integral von $-\infty$ bis $x$ über deren Dichtefunktion und gibt die Wahrscheinlichkeit an, dass eine Zufallsvariable $X$ einen Wert kleiner/gleich $x$ annimmt. Durch Transformation der normalverteilten Zufallsvariable $X$ in eine Standardnormalverteilung ergibt sich

$$\begin{equation}
  P(X \le x) = F(x) \equiv P\left(Z \le \frac{x - \mu}{\sigma}\right) = \Phi\left(\frac{x - \mu}{\sigma}\right)
(\#eq:cdf1)\end{equation}$$

und ermöglicht das Ablesen der Funktionswerte aus nur einer einzigen Tabelle, wie sie in Tabelle XYZ aufgeführt ist. Durch verschiedene Umformungen der Gleichung \@ref(eq:cdf1) lassen sich weitere Fragestellungen bezüglich der Wahrscheinlichkeit lösen:

$$\begin{equation}
  P(X \ge x) = 1 - \Phi\left(\frac{x - \mu}{\sigma}\right)
(\#eq:cdf2)\end{equation}$$

$$\begin{equation}
  P(x_1 \le X \le x_2) = \Phi\left(\frac{x_2 - \mu}{\sigma}\right) - \Phi\left(\frac{x_1 - \mu}{\sigma}\right)
(\#eq:cdf3)\end{equation}$$

#### Berechnung per Hand

Angenommen die Punkteverteilung in Statistikklausuren folgt approximativ einer Normalverteilung mit $\mu = 40$ und $\sigma = 10$. Wie hoch ist die Wahrscheinlichkeit, die Klausur nicht zu bestehen, wenn eine Klausur ab 30 Punkten als bestanden gilt und Punkte in 0.5er-Schritten vergeben werden? Aus Gleichung \@ref(eq:cdf1) ergibt sich $P(X \le 29.5) = \Phi\left(\frac{29.5 - 40}{10}\right) = \Phi(-1.05)$. Entsprechend der Tabelle \@ref(tab:diststd) lässt sich ablesen, dass $\Phi(-1.05)$ = $1 - \Phi(1.05)$ ist, womit $P(X \le 29.5) = 1 - 0.8531 = 0.1469$ ist. Die Wahrscheinlichkeit, die Klausur nicht zu bestehen, beträgt also 14.69\%.

#### Berechnung mit R

```{r}
pnorm(29.5, mean = 40, sd = 10)
pnorm(-1.05, mean = 0, sd = 1)
```

### Quantilsfunktion

Die Quantilsfunktion $F^{-1}(x)$ der Normalverteilung ist nichts anderes als die Umkehrfunktion der Verteilungsfunktion $F(x)$. Im Gegensatz zur Verteilungsfunktion, welche für ein gegebenes Quantil $\tilde{x}_p$ das entsprechende $p$ des liefert, gibt die Quantilsfunktions für ein gegebenes $p$ das entsprechende Quantil $\tilde{x}_p$ zurück. Zur Bestimmung schlägt man zunächst das am nächsten zu $p$ liegende Quantil $\tilde{z}_p$ in der Verteilungstabelle der Standardnormalverteilung nach und transformiert es zurück in das Quantil $\tilde{x}_p$ der tatsächlichen Normalverteilung. Somit ist also

$$\begin{equation}
  F^{-1}(x) = \tilde{x}_p = \mu + \sigma \cdot \tilde{z}_p,
(\#eq:icdf)\end{equation}$$
  
wobei auch hier die Umformungen aus dem vorherigen Abschnitt angewendet werden können.

#### Berechnung per Hand

Es gilt wieder, dass die Punkteverteilung in Statistikklausuren approximativ einer Normalverteilung mit $\mu = 40$ und $\sigma = 10$ folgt. Ab wie viel Punkten gehört man zu den oberen 10\%? Das am nächsten zu $p = 1 - 0.1 = 0.9$ liegende Quantil ist entsprechend der Verteilungstabelle der Standardnormalverteilung (Tabelle \@ref(tab:diststd)) $1.28$. Aus Formel \@ref(eq:icdf) ergibt sich also $\tilde{x}_{0.9} = 40 + 10 \cdot 1.28 = 52.8$, womit man ab 52.8 Punkten zu den oberen 10\% der Klausurteilnehmer gehört.

#### Berechnung mit R

```{r}
qnorm(0.9, mean = 40, sd = 10) 
```


## Übungsaufgaben

Mit Hilfe dieser Aufgaben kann zum einen das rechnerische Handwerkszeug trainiert werden, als auch die Anwendung von statistischen Methoden und der Transfer von statistischer Theorie auf konkrete Problemstellungen. Der Schwierigkeitsgrad der Aufgaben ist bewusst sehr hoch gewählt, sodass Sie an den Aufgaben tüfteln und theoretisches Verständnis einbringen müssen, statt nur Stumpf ein Schema F anzuwenden. Sind Sie in der Lage die Aufgaben selbstständig zu lösen und können dabei Ihre Lösungen und Lösungsschritte nachvollziehen, dann werden Sie keinerlei Probleme haben, auch abgewandeltete Aufgabenstellungen in der Klausur lösen zu können.

```{r echo = FALSE, tidy = TRUE}
data.revenues <- c(100, 120, 110, 90, 140, 150, 600, 130, 110)
```

**Aufgabe 1 (Skalenniveaus, Lagemaße, Streuungsmaße, Robustheit)** 

In Ihrem Unternehmen sind in den vergangenen `r length(data.revenues)` Monaten die folgenden Umsatzerlöse *[in TEUR]* realisiert worden: $x = (`r paste0(data.revenues[1:3], collapse=', ')`)$ für Q3/18, $x = (`r paste0(data.revenues[4:6], collapse=', ')`)$ für Q4/18 und $x = (`r paste0(data.revenues[7:9], collapse=', ')`)$ für Q1/19. Sie sind mit der Erstellung eines Geschäftsberichts beauftragt worden, wofür Sie die Umsatzzahlen deskriptiv zusammenfassen müssen.

a. Welches Skalenniveau besitzt die zu analysierende Variable und welche statistischen Lage- und Streuungsmaße sind demnach valide anwendbar?
b. Wie hoch war der sowohl durchschnittliche als auch typische Umsatz pro Monat über den Zeitraum von Q3/18 bis Q4/18?
c. Wie weit waren im Zeitraum von Q3/18 bis Q4/18 die einzelnen Umsätze vom durchschnittlichen Umsatz entfernt und welcher Umsatz wurde in 75% der Fälle nicht überschritten?
d. Wie hat sich der sowohl durchschnittliche als auch typisiche Umsatz in Q1/19 im Vergleich zu Q4/18 relativ verändert? Was fällt Ihnen beim Vergleich der beiden Ergebnisse aus und was ist die Ursache dafür? Welchen Wachstumswert würden Sie in den Geschäftsbericht schreiben?

**Aufgabe 2 (Skalenniveaus, Lagemaße, Streuungsmaße)**

```{r echo = FALSE, tidy = TRUE}
data.abc <- ordered(rep(ordered(c("A", "B", "C")), c(100, 400, 400)), levels = c("C", "B", "A"))
```

Ihre Kunden sind gemäß ihres Anteils am Gesamtumsatz in A-, B- und C-Kunden klassifiziert, wobei A-Kunden die anteilig umsatzstärksten und C-Kunden die anteilig umsatzschwächsten Kunden sind. Insgesamt haben Sie `r tally(data.abc)["C"]` C-Kunden, `r tally(data.abc)["B"]` B-Kunden und `r tally(data.abc)["A"]` A-Kunden. Tipp: Vereinfachen Sie sich den Berechnungsaufwand mit Hilfe einer geeigneten Stichprobe.

a. Welches Skalenniveau besitzt die zu analysierende Variable und welche statistischen Lage- und Streuungsmaße sind demnach valide anwendbar?
b. Sollte die Variable mit Hilfe eines Balkendiagramms oder eines Histogramms visualisiert werden? Begründen Sie Ihre Antwort!
c. Ist Ihr typischer Kunde ein A-, B- oder C-Kunde? Zwischen welchen beiden Klassen liegen dabei die mittleren 50% Ihrer Kunden? 

**Aufgabe 3 (Zusammenhangsmaße, Korrelation, Störvariablen, Robustheit)**

```{r echo = FALSE}
data.marketingexp <- data.frame(Werbeausgaben = c(50, 75, 100, 125, 160, 20), Gewinn = c(10, 12, 14, 15, 16, 17))
data.marketingexp$ROI = data.marketingexp$Gewinn / data.marketingexp$Werbeausgaben
```

Zur Überprüfung der Wirksamkeit der unternehmerischen Marketingkampagnen, wollen Sie analysieren, in wie weit es einen Zusammenhang zwischen den Werbeausgaben ($x$) und dem Gewinn ($y$) *[jeweils in TEUR]* gibt. Für Ihre Analyse stehen Ihnen die relevanten Daten der vergangenen `r nrow(data.marketingexp[1:5,1:2])` Monate zur Verfügung:

```{r echo = FALSE}
knitr::kable(t(data.marketingexp[1:5,1:2]), row.names = TRUE, booktabs = TRUE, escape = FALSE)
```

a. Welchen Effekt haben die Werbeausgaben auf den unternehmerischen Gewinn? *(Hinweis: $\mathit{0.1 \le \lvert r \rvert \lt 0.3}$: Kleiner Effekt, $\mathit{0.3 \le \lvert r \rvert \lt 0.5}$: Mittlerer Effekt, $\mathit{\lvert r \rvert \ge 0.5}$: Starker Effekt)*
b. Können Sie sicher sagen, dass es einen kausalen Zusammenhang zwischen den Werbeausgaben und dem Gewinn gibt? Begründen Sie Ihre Antwort!
c. Ein Kollege behauptet auf Basis der von Ihnen durchgeführten Korrelationsanalyse, man müsse nur die Werbeausgaben erhöhen, damit auch der unternehmerische Gewinn ansteigt. Zeigen Sie ihm rechnerisch mittels einer geeigneten Korrelationsanalyse, dass daraus sogar ein negativer Effekt resultieren kann.
d. Angenommen in einem zusätzlichen 6. Monat betragen die Werbeausgaben 17 TEUR; der Gewinn aufgrund schwacher Konjunktur jedoch nur 20 TEUR. Welchen Einfluss hätte dies auf den in Aufgabenteil a) ermittelten Effekt? Begründen Sie Ihre Antwort! *(Hinweis: Eine Rechnung ist nicht erforderlich)*

**Aufgabe 4 (Boxplot, Streuungsmaße, Ausreißer, Robustheit, Forschungsprozess, Null- und Alternativhypothese, Störvariablen)**

```{r echo = FALSE}
set.seed(1909)
data.conversions <- data.frame(Conversions = c(round(rnorm(60, mean = 800, sd = 100), 0), round(rnorm(60, mean = 700, sd = 80), 0)), Werbekanal = rep(c("FACEBOOK", "ADSENSE"), c(60, 60)))
```

Das Unternehmen, für welches Sie tätig sind, schaltet hauptsächlich Werbeanzeigen über Facebook und Google AdSense. Sie möchten herausfinden, welches der beiden Werbekanäle hinsichtlich der Conversions historisch am wirksamsten war. Dafür stehen Ihnen für jeden Werbekanal die monatlichen Conversions der vergangenen 5 Jahre zur Verfügung, die im nachfolgenden Boxlplot visualisiert sind:

```{r, echo = FALSE, fig.align = "center"}
ggplot(data = data.conversions, aes(y = Conversions, x = Werbekanal)) +
  geom_boxplot() +
  theme_ipsum_rc(plot_margin = margin(0, 0, 0, 0)) +
  theme(legend.position = "bottom") 
```

Neben der obrigen Abbildung stehen Ihnen außerdem noch die nachfolgenden Deskriptivstatistiken für Ihre weitere Analyse zur Verfügung:

```{r, echo = FALSE}
knitr::kable(favstats(Conversions ~ Werbekanal, data = data.conversions), row.names = TRUE, booktabs = TRUE, escape = FALSE)
```

a. Beschreiben Sie ausführlich mit Hilfe des Boxplots und der Deskriptivstatistiken, welche Beobachtungen Sie machen können. Übertragen Sie auch wichtige Deskriptivstatistiken in das Boxplot.
b. Welche praxisbezogene Forschungsfrage würden Sie auf Basis Ihrer Beobachtungen formulieren? Operationalisieren Sie außerdem Ihre Forschungsfrage als eine statistische Null- und Alternativhypothese!
c. In wie weit schwanken die mittleren 50% der Conversions sowohl für Facebook als auch für Google AdSense? Fällt Ihnen im Vergleich zu den gegebenen Deskriptivstatistiken etwas ungewöhnliches auf? Was könnte dir Ursache dafür sein?
d. Ab wann würden sowohl für Facebook als auch für Google AdSense einzelne Conversions als Ausreißer gelten? Welchen Einfluss hätten diese auf weitere statistische Analysen?
e. Angenommen es gäbe eine signfikanten Unterschied hinsichtlich der Conversions in Abhängigkeit des Werbekanals. Stehen die Conversions und Werbekanäle dann auch in einem kausalen Zusammenhang? Begründen Sie Ihre Antwort und geben Sie ein Beispiel dafür, wie Sie Ihre Analyse verbessern und treffender machen könnten.

**Aufgabe 5 (Normalverteilung, Verteilungsdiagramme, Schiefe, Robustheit)**

```{r echo = FALSE}
set.seed(1909)
data.sales <- rnbinom(1825, 5, 0.5) * 10
```

Als Ergebnis einer initialen Analyse täglicher Absatzmengen *[in Tausend Stück]* über die vergangenen 5 Jahre hat sich das nachstehende Verteilungs- und Quantil-Quantil-Diagramm realisiert:

```{r, echo = FALSE, fig.align = "center"}

grid.arrange(
  ggplot(data = data.frame(x = data.sales), aes(x = x)) +
    geom_bar() +
    labs(x = "Absatzmenge [in Tausend Stück]", y = "Häufigkeit") +
    theme_ipsum_rc(plot_margin = margin(0, 10, 0, 0)) +
    theme(legend.position = "bottom"),
  ggplot(data = data.frame(x = data.sales), aes(sample = x)) +
    stat_qq() +
    stat_qq_line() + 
    labs(x = "Theoretische Quantile", y = "Empirische Quantile") +
    theme_ipsum_rc(plot_margin = margin(0, 00, 0, 0)) +
    theme(legend.position = "bottom"),
  nrow = 1
)
```

a. Welches Skalenniveau besitzt die zu analysierende Variable? Geben Sie dabei auch an, ob es sich um eine diskrete oder stetige Variable handelt und um welche Art von Verteilungsdiagramm es sich handelt. Begründen Sie Ihre Antworten!
b. Beschreiben Sie ausführlich, welche Beobachtungen Sie auf Basis des Verteilungsdiagramms machen können. Gehen Sie dabei auch auf die Schiefe und Modalität der Verteilung ein.
c. Welche Aussage können Sie hinsichtlich der Lage von Mittelwert und Median in der Verteilung treffen? Begründen Sie Ihre Antwort!
d. Erläutern Sie den Aufbau des oben dargestellten Quantil-Quantil-Diagramms und wie dieses zur Überprüfung einer Normalverteilungsannahme eingesetzt werden kann.
e. Nennen Sie eine Möglichkeit die Daten so zu veränderen, dass die daraus resultierende Verteilung annährend normalverteilt ist. Aus welchem Grund kann dies erforderlich sein? 

**Aufgabe 6 (Normalverteilung, Verteilungsfunktion, Quantilsfunktion, Z-Transformation, 68-95-99,7%-Regel)**

Da Ihr Unternehmen in Kürze ein neues Produkt veröffentlichen wird, hat man Sie zur Abschätzung einer unverbindlichen Preisempfehlung beauftragt zu ermitteln, wie viel Geld *[in EUR]* die deutschen Mitbürger bereit wären, für das neue Produkt zu bezahlen. Sie haben daher eine repräsentative Stichprobe erhoben, in welcher Sie 1000 Menschen das neue Produkt vorgestellt und anschließend gefragt haben, wie viel Euro sie nun dafür zahlen würden. In der Stichprobe zeigt sich, dass das interessierende Merkmal approximativ einer Normalverteilung mit $\mu = 50$ und $\sigma = 5$ folgt.

a. Wie viel Geld würde der sowohl durchschnittliche als auch typische Mitbürger für das neue Produkt bezahlen? Begründen Sie Ihre Antwort!
b. In welcher Preisspanne bewegen sich die mittleren 95% Ihrer Befragungen? 
c. Welchen Preis sind die unteren 0.15% der Menschen maximal bereit zu zahlen bzw. welchen Preis sind die die oberen 2.5% der Menschen mindestens bereit für das neue Produkt zu bezahlen. Begründen Sie Ihre Antwort!
d. Wie viel Prozent der Menschen wären bereit dazu, einen Preis oberhalb von 65 EUR bzw. einen Preis unterhalb von 40 EUR bezahlen? Begründen Sie Ihre Antwort!

<!-- 
68% der Werte im Bereich μ±1·σ, 84-16
95% der Werte im Bereich μ±2·σ, 97.5 - 2.5
99,7% der Werte im Bereich μ±3·σ, 99.85 - 0.15
//-->

**Aufgabe 7 (Normalverteilung, Verteilungsfunktion, Quantilsfunktion, Z-Transformation)**

```{r data.returns, echo = FALSE}
data.returns = rnorm(n = 255, mean = 0.2, sd = 0.15)
data.returns.quantiles <- quantile(data.returns, probs = c(0.01, 0.05, 0.95, 0.99))
```

Als Portfoliomanager einer Versicherung investieren Sie in diverse Portfolios zur Erzielung kurzfristiger Handelsgewinne auf eigene Rechnung. Portfolio A hat in den vergangenen 255 Tagen eine durchschnittliche Rendite von 2% bei einer Schwankungsbreite von 1.5% realisiert, wohingegen Portfolio B im selben Zeitraum eine durchschnittliche Rendite von 3% bei einer Schwankungsbreite von 2% realisiert hat. Für die historischen Renditen von Portfolio A sind außerdem noch die folgenden Quantile bekannt:

```{r echo = FALSE, results = 'asis'} 
knitr::kable(t(data.returns.quantiles), booktabs = TRUE, escape = FALSE)
```

a) Welchen Betrag werden Sie mit einer Wahrscheinlichkeit von 99% innerhalb eines Handelstages nicht verlieren, wenn Sie heute 50.000 EUR in Portfolio A investieren wollen?
b) Aus Gründen der Risikosteuerung, darf mit einer Wahrscheinlichkeit von 95% der Verlust innerhalb eines Tages nicht größer als 3.000 EUR sein. Welchen Betrag dürfen Sie daher maximal in das Portfolio A anlegen?
c) Das Portfolio A hat am nächsten Handelstag eine Rendite von 3.5% realisiert; Portfolio B dagegen eine Rendite von 4%. Welches Portfolio hat statistisch besser abgeschnitten?

**Aufgabe 8 (Inferenz von Anteilen mittels Nullverteilung, Null- und Alternativhypothese, Nullverteilung, p-Wert)**

```{r data.sla, echo = FALSE, cache = TRUE}
data.sla.sample = rep(factor(c(FALSE, TRUE)), c(34, 467))
data.sla.nulldist <- do(10000) * rflip(n = 500, prob = 0.95)
data.sla.quantiles <- quantile(~ prop, data = data.sla.nulldist, probs = c(0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975))
```

Ihr Lieferant garantiert Ihnen im Rahmen eines Service-Level-Agreements (SLA), dass dieser Waren in 95% der Fälle innerhalb von 7 Tagen ab Bestelleingang zustellt. Um eine Idee davon zu bekommen, wie sich Stichproben realisieren müssten, wenn die Aussage des Herstellers stimmt, haben Sie eine entsprechende Nullverteilung simuliert, deren Quantile wie folgt lauten:

```{r echo = FALSE, results = 'asis'} 
knitr::kable(t(data.sla.quantiles), booktabs = TRUE, escape = FALSE)
```

Leider stehen Ihnen nicht alle Bestellungen der Vergangenheit zur Verfügung sondern nur 500 zufällig ausgewählte Bestellungen. Dabei haben Sie festgestellt, dass bei 34 Bestellungen die Zustellung nicht innerhalb von 7 Tagen erfolgt ist. 

a. In viel Prozent der Fälle ist innerhalb dieser Stichprobe das SLA eingehalten worden? Können Sie bereits jetzt sicher sagen, dass Ihr Lieferant das SLA verletzt? Begründen Sie Ihre Antwort!
b. Da sich auf Basis der Stichprobe der Verdacht erhärtet hat, dass der Lieferant zu Ihren Lasten gegen das SLA verstößt, möchten Sie ihm dies im Rahmen eines statistischen Signifikanztests nachweisen. Formulieren Sie dazu zunächst die statistische Null- und Alternativhypothese und führen Sie anschließend eine Hypothesenprüfung zu einem 5%-Signifikanzniveau $(\alpha = 0.05)$ durch.
c. Hält der Lieferant sein SLA ein oder nicht? Begründen Sie Ihre Antwort!
d. Erwarten Sie ein p-Wert größer oder kleiner 5%? Begründen Sie Ihre Antwort!

**Aufgabe 9 (Inferenz von Mittelwerten mittel Nullverteilung, Null- und Alternativhypothese, Nullverteilung)**

```{r data.gin, echo = FALSE, cache = TRUE}
data.gin.sample = 1001.1421
data.gin.nulldist <- do(10000) * mean(rnorm(n = 250, mean = 1000, sd = 10))
data.gin.quantiles <- quantile(~ mean, data = data.gin.nulldist, probs = c(0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975))
```

Der Hersteller einer Maschine, die Sie betrieblich zur Abfüllung von Gin verwenden, garantiert Ihnen eine approximativ normalverteile Füllmenge von durchschnittlich 1000ml pro Flasche bei einer Fehlertoleranz von 0.01%. Sie vermuten, dass die Maschine die garantierte durchschnittliche Füllmenge nicht einhält und haben daher eine Nullverteilung simuliert, deren Quantile wie folgt lauten:

```{r echo = FALSE, results = 'asis'} 
knitr::kable(t(data.gin.quantiles), booktabs = TRUE, escape = FALSE)
```

Auf Basis einer Stichprobe von 250 zufällig ausgewählten Flaschen ergibt sich empirisch eine durchschnittliche Füllmenge von $`r data.gin.sample`$ml pro Flasche.

a. Angenommen es würde gelten, was der Hersteller garantiert. Wodurch kann dann ein solches Stichprobenergebnis zu Stande kommen?
b. Formulieren Sie eine statistische Null- und Alternativhypothese mit der Sie im Rahmen eines Hypothesentests prüfen können, ob die durchschnittlich garantierte Füllmenge eingehalten wird oder nicht.
c. Führen Sie einen Signifikanztest auf Basis Ihres aufgestellten Hypothesenpaars mit einer Irrtumswahrscheinlichkeit von 5% durch und interpretieren Sie Ihr Ergebnis.
d. Können Sie sicher sagen, ob der festgestellte signifikante Unterschied zu Ihren Gunsten oder zu Gunsten des Herstellers ausfällt? Begründen Sie Ihre Antwort!
e. Angenommen Sie möchten statistisch signifikant $(\alpha = 0.05)$ überprüfen, dass die Maschine durchschnittlich mehr abfüllt. Zu welchem Ergebnis kommen Sie dann? Begründen Sie auch hier Ihre Antwort und erläutern Sie darüber hinaus, warum es wichtig ist, dass eine Überprüfung von gerichteteten Hypothesen nicht nur durch empirische Daten begründet sein darf.

**Aufgabe 10 (Inferenz von Mittelwerten mittels Bootstrap-Verteilung, Null- und Alternativhypothese, Generalisierbarkeit)**

```{r data.macces, echo = FALSE, cache = TRUE}
data.macces.sample = rnorm(300, mean = 4, sd = 4)
data.macces.bootstrap <- do(10000) * mean(resample(data.macces.sample))
data.macces.quantiles <- quantile(~ mean, data = data.macces.bootstrap, probs = c(0, 0.025, 0.05, 0.5, 0.95, 0.975, 1))
```

Das zentrale Werbeversprechen eines ausschließlich auf dem deutschen Markt tätigen Systemgastronomie-Konzerns lautet, dass jeder Kunde maximal fünf Minuten zwischen Bestellung und Essensausgabe warten muss. Als Gesamtverantwortlicher für das Auditing wollen Sie dieses Versprechen auf Einhaltung überprüfen und haben daher ohne Ankündigung in 10 Ihrer insgesamt 500 Filialen 30 Testesser zum gleichen Zeitpunkt die Wartezeit bei einer identischen Bestellung ermitteln lassen und auf Basis der Daten eine Bootstrap-Verteilung simuliert, deren Quantile wie folgt lauten:

```{r echo = FALSE, results = 'asis'} 
knitr::kable(t(data.macces.quantiles), booktabs = TRUE, escape = FALSE)
```

a. Kann das Werbeversprechen, dass die Wartezeit unterhalb 5 Minuten beträgt, eingehalten werden? Formulieren Sie zunächst die Null- und Alternativhypothese und prüfen Sie dann zu einem Signifikanzniveau von 5% $(\alpha = 0.05)$. Zu welchem begründeten Ergebnis kommen Sie und was schlussfolgern Sie daraus?
b. Ist Ihr Ergebnis generalisierbar? Begründen Sie Ihre Antwort!

**Aufgabe 11 (Inferenz von Mittelwertsunterschieden mittels Bootstrap-Verteilung, Null- und Alternativhypothese, Standardfehler, Fehlerarten, Kausalität)**

```{r echo = FALSE, cache = TRUE}
data.packaging <- data.frame(Y = rnorm(1000, mean = 600, sd = 1200), N = rnorm(1000, mean = 540, sd = 1200))
data.packaging$D = data.packaging$Y - data.packaging$N
data.packaging.bootstrap <- do(10000) * mean(resample(data.packaging$D))
data.packaging.bootstrap.quantiles <- quantile(~ mean, data = data.packaging.bootstrap, prob = c(0, 0.025, 0.05, 0.5, 0.95, 0.975, 1))
```

Im Rahmen eines A/B-Tests wollen Sie prüfen, ob ein neues Produktdesign einen positiven Einfluss auf die Absatzmengen in einem Supermarkt hat. Das Produkt mit dem neuen Design (30 Beobachtungen) wurde durchschnittlich etwa `r round(mean(data.packaging$Y), 0)` $(\bar x_N)$ Mal pro Tag verkauft. Mit dem alten Design (30 Beobachtungen) durchschnittlich nur etwa `r round(mean(data.packaging$N), 0)` $(\bar x_A)$ Mal. Hinsichtlich der Stichprobendifferenz zwischen der durschnittlichen Absatzmenge des Produktes mit neuem Design und des Produktes mit altem Design $(\bar x_N - \bar x_A)$ haben Sie im Rahmen einer Simulation eine Bootstrap-Verteilung ermittelt, deren Quantile wie folgt lauten:

```{r echo = FALSE, results = 'asis'} 
knitr::kable(t(data.packaging.bootstrap.quantiles), booktabs = TRUE, escape = FALSE)
```

a. Hat das neue Produktdesign einen signifikanten positiven Einfluss auf die durchschnittlichen Absatzmengen? Formulieren Sie zunächst die Null- und Alternativhypothese und prüfen Sie dann zu einem Signifikanzniveau von 5% $(\alpha = 0.05)$. Zu welchem begründeten Ergebnis kommen Sie und was schlussfolgern Sie daraus?
b. Obwohl die Stichprobe einen recht deutlichen Unterschied zwischen neuem und altem Produktdesign gezeigt hat, konnten Sie keinen signifikanten Effekt nachweisen. Was könnte statistisch betrachtet die Ursachen dafür sein? Beziehen Sie sich bei Ihren Ausführungen ausdrücklich auf den Standardfehler und dessen Wirkungsweise auf das Konfidenzintervall.
c. Angenommen Sie hätten nachgewiesen, dass das neue Produktdesign tatsächlich einen signifikanten positiven Einfluss auf die durchschnittliche Absatzmenge hat. Welcher Fehler wäre es, wenn es in der Realität wirklich keinen Einfluss gäbe und wie lässt sich die Fehlerwahrscheinlichkeit reduzieren?
d. Gibt es auch einen kausalen Zusammenhang zwischen dem Produktdesign und den Absatzmengen? Begründen Sie Ihre Antwort!

**Aufgabe 12 (Lineare Einfachregression, Metrische Prädiktoren, Bootstrap-Simulation)**

Sie sind damit beauftragt worden, dass mit der geplanten Investition in eine Aktie übernommene Marktrisiko zu ermitteln. In Ihrer Stichprobe stehen Ihnen dafür über die vergangenen 255 Handelstage sowohl die täglichen Renditen der Aktie als die Marktrenditen eines Marktportfolios (DAX30) zur Verfügung. Mittels der Methode der kleinsten Quadrate haben Sie basierend auf Ihrer Stichprobe folgendes Regressionsmodell geschätzt: 

```{r echo = FALSE, cache = TRUE}
data.capm.returns = data.frame(index = rnorm(255, .01, .05))
data.capm.returns$stock <- 0.01 * data.capm.returns$index + rnorm(255, .01, .003)
data.capm.returns$index <- data.capm.returns$index  * 100
data.capm.returns$stock <- data.capm.returns$stock  * 100
data.capm.lm <- summary(lm(stock ~ index, data = data.capm.returns))
data.capm.bootstrap <- do(10000) * lm(stock ~ index, data = resample(data.capm.returns))
data.capm.bootstrap.quantiles <- quantile(~ index, data = data.capm.bootstrap, prob = c(0, 0.025, 0.05, 0.5, 0.95, 0.975, 1))

```

$$
  \hat R_{AKTIE} = `r data.capm.lm$coef[1]` + `r data.capm.lm$coef[2]` \cdot R_{MARKT}
$$

Darüber hinaus ist hinsichtlich des $\beta_{MARKT}$-Koeffizienten eine Bootstrap-Verteilung simuliert werden, deren Quantile auszugsweise wie folgt lauten: 

```{r echo = FALSE, results = 'asis'} 
knitr::kable(t(data.capm.bootstrap.quantiles), booktabs = TRUE, escape = FALSE)
```

a. Quantifizieren Sie das Marktrisiko! Geben Sie dazu an, wie die erwartete Rendite der Aktie sich verändert, wenn die Rendite des Marktportfolios eine Änderung um einen Prozentpunkt erfährt und was lässt sich somit über die Aktie schlussfolgern?
b. Wie hoch wäre theoretisch die erwartete Rendite der Aktie, wenn eine Marktendite in Höhe von 5\% realisiert worden wäre?
c. Hat der Markt auch einen statistisch signifikanten Einfluss auf die Rendite der Aktie? Formulieren Sie zunächst die Null- und Alternativhypothese und prüfen Sie dann zu einem Signifikanzniveau von 5% $(\alpha = 0.05)$. Geben Sie dabei auch den/die relevanten Ablehnungsbereich/e sowie die verwendete Teststatistik an. Zu welchem begründeten Ergebnis kommen Sie und was schlussfolgern Sie daraus?

### Lösungshinweise

**Aufgabe 1**

a. Die Variable *Umsatzerlös* besitzt metrisches Skalenniveau. Demnach sind Modus, Mittelwert, Median und Quantile als Lagemaße sowie Varianz, Standardabweichung und Interquartilsabstand als Streuungsmaße zulässig.
b. Der durchschnittliche Umsatz (Mittelwert) im Zeitraum zwischen Q3/18 und Q4/18 war $\bar x = `r round(mean(data.revenues[1:6]), 2)`$ TEUR *(Formel \@ref(eq:mean))* pro Monat und der typische Umsatz (Median) war $\tilde x_{0.5} = `r round(median(data.revenues[1:6]), 2)`$ TEUR *(Formel \@ref(eq:quantiles))* pro Monat.
c. Im Zeitraum zwischen Q3/18 und Q4/18 schwankte der Umsatz pro Monat durchschnittlich um $s_x \approx `r round(sd(data.revenues[1:6]), 2)`$ TEUR *(Formel \@ref(eq:std))*. Ein Umsatz in Höhe von $\tilde x_{0.75} = 140$ TEUR *(Formel \@ref(eq:quantiles))* wurde im Betrachtungszeitraum in 75% der Fälle nicht überschritten.
d. Der durchschnittliche Umsatz in Q4/18 war $\bar x = `r round(mean(data.revenues[4:6]), 2)`$ TEUR *(Formel \@ref(eq:mean))* und der typische Umsatz war $\tilde x_{0.5} = `r round(median(data.revenues[4:6]), 2)`$ TEUR *(Formel \@ref(eq:quantiles))*. In Q1/2019 war $\bar x = `r round(mean(data.revenues[7:9]), 2)`$ TEUR *(Formel \@ref(eq:mean))* und $\tilde x_{0.5} = `r round(median(data.revenues[7:9]), 2)`$ TEUR. Der durchschnittliche Umsatz ist demnach um `r round((mean(data.revenues[7:9])/mean(data.revenues[4:6])-1)*100, 2)`% gestiegen und der typische Umsatz sogar um `r round((median(data.revenues[7:9])/median(data.revenues[4:6])-1)*100, 2)`% gefallen. Der Umsatz in Höhe von 600 TEUR ist verglichen zu den übrigen Umsätzen ein eher außergewöhnlicher und atypischer Wert und kann demnach als Ausreißer klassifiziert werden. Der Mittelwert erhöht sich gegenüber dem Median deutlich, da der Mittelwert nicht robust gegenüber Ausreißern ist und diesen hier entsprechend bei der Berechnung mit berücksichtigt.

**Aufgabe 2**

a. Die Variable *Kundegruppe* besitzt ordinales Skalenniveau, da sich die Gruppen nach ihrer Wertigkeit sortieren lassen. Demnach sind Modus, Median und Quantile als Lagemaße sowie der Interquartilsabstand als Streuungsmaß zulässig.
b. Da es sich bei der Variable um eine diskrete Variable handelt, ist nur das Balkendiagramm für eine Visualisierung geeignet. 
c. Stichprobe mit 4 C-, 4 B- und 1 A-Kunden. $\tilde x_{0.5} = B$ *(Formel \@ref(eq:quantiles))*. Der typische Kunde ist somit ein B-Kunde. Die mittleren 50% der Kunden verteilen sich zwischen Klasse C und Klasse B ($\tilde x_{0.75} = B, \tilde x_{0.25} = C$ *(Formel \@ref(eq:quantiles))*), d.h. der Interquartilsabstand liegt zwischen C und B *(Formel \@ref(eq:iqr))*. Denken Sie an die aufsteigende Sortierung der Urliste!

**Aufgabe 3**

a. Der Korrelationskoeffizient beträgt $r = `r round(cor(Gewinn ~ Werbeausgaben, data = data.marketingexp[1:5,1:2]), 4)` = `r round(cor(Gewinn ~ Werbeausgaben, data = data.marketingexp[1:5,1:2]) * 100, 2)`$ *(Formel \@ref(eq:cor))*. Somit liegt ein positiver linearer Zusammenhang mit starkem Effekt zwischen den Werbeausgaben und dem Gewinn vor. Mit steigenden Werbeausgaben erhöht sich demnach auch der Gewinn.
b. Die Korrelationsanalyse zeigt nur, dass es statistischen Zusammenhang gibt, allerdings belegt Sie keinen kausalen Zusammenhang, da u.a. mögliche Störfaktoren, die den unternehmerischen Gewinn nebst der Werbeausgaben zusätzlich beeinflussen, nicht kontrolliert werden. 
c. Betrachtet man die Werbeausgaben als Investition und nutzt man die Rendite (gemessen am Gewinn im Verhältnis zum eingesetzten Kapital) als abhängige Variable, so ergibt sich ein Korrelationskoeffizient in Höhe von $r = `r round(cor(ROI ~ Werbeausgaben, data = data.marketingexp[1:5,1:3]), 4)` = `r round(cor(ROI ~ Werbeausgaben, data = data.marketingexp[1:5,1:3]) * 100, 2)`\%$ *(Formel \@ref(eq:cor))*. Somit liegt sogar ein negativer linearer Zusammenhang mit starkem Effekt vor. Mit steigenden Werbeausgaben verringert sich demnach auch die Rendite. *(Hinweis: Analyse des Trinkgelddatensatzes mit zur Rechnung relativem Trinkgeld als abhängige Variable)*
d. Im Vergleich zu den anderen Monaten handelt es sich beim Gewinn des 6. Monats um einen deutlichen Ausreißer nach unten. Da bei der Berechnung der Kovarianz und des Korrelationskoeffizienten die gegenüber Aureißer anfälligen Mittelwerte von $x$ und $y$ verwendet werden, ist entsprechend auch der Korrelationskoeffizient anfällig gegenüber Ausreißern. Somit ist auch zu erwarten, dass sich der in Aufgabenteil a) ermittelte Effekt deutlich reduziert. 

**Aufgabe 4**

a. Durchschnittlich betrachtet haben Werbeanzeigen bei Facebook zu höheren Conversions geführt als bei Google AdSense. Der Vergleich zwischen Mittelwert und Median zeigt für Google AdSense, dass es sich um eine annäherend symmetrische Verteilung mit leichter Tendenz zur Rechtsschiefe handelt, die möglicherweise durch Ausreißer oberhalb des Q3 begründet ist. Auch bei Facebook zeigt sich eine annährend symmetrische Verteilung, jedoch existiert hier eine leichte Tendenz zur Linksschiefe, da der Mittelwert links vom Median liegt. Dies wiederum ist möglicherweise durch Ausreißer unterhalb des Q1 begründet. Hinsichtlich der Schwankungsbreite zeigt sich bei Facebook eine höhere durchschnittliche Streuung um den Mittelwert als bei Google AdSense.
b. Auf Basis der Beobachtungen ließe sich die Forschungsfrage stellen, ob die Wahl des Werbekanals einen Einfluss auf die Conversions hat. Entsprechend könnte $H_0: \mu_{ADSENSE} \ge \mu_{FACEBOOK}$ und $H_A: \mu_{ADSENSE} \lt \mu_{FACEBOOK}$ sein. Hierbei ist allerdings zu bemerken, dass sich diese Hypothesen rein auf die Daten stützen und dass eigentlich ein durch Literatur begründeter Erklärungsansatz genannt werden müsste, der die Hypothesen begründet stützt.
c. Die mittleren 50% der Conversions schwanken für Facebook um $IQR=`r iqr(Conversions ~ Werbekanal, data = data.conversions)["FACEBOOK"]`$ *(Formel \@ref(eq:iqr))* und für Google AdSense um $IQR=`r iqr(Conversions ~ Werbekanal, data = data.conversions)["ADSENSE"]`$ *(Formel \@ref(eq:iqr))*. Verglichen zu den jeweiligen Standardabweichungen liegen diese beiden Werte darüber, was wiederum auf Ausreißer zurückzuführen ist. Da bei der Berechnung der Varianz und der Standardabweichung der gegenüber Aureißer anfällige Mittelwerte verwendet wird, ist entsprechend auch die Standardabweichung anfällig gegenüber Ausreißern, wohingegen der Interquartilsabstand robust bliebt, da sich aus den robusten Quantilen ermittelt.
d. Für Facebook sind Conversions oberhalb von `r iqr(Conversions ~ Werbekanal, data = data.conversions)["FACEBOOK"] * 1.5 + quantile(Conversions ~ Werbekanal, data = data.conversions, probs = 0.75)["75%"][2,1]` und unterhalb von `r iqr(Conversions ~ Werbekanal, data = data.conversions)["FACEBOOK"] * -1.5 + quantile(Conversions ~ Werbekanal, data = data.conversions, probs = 0.25)["25%"][2,1]` als Ausreißer zu deklarieren. Für Google AdSense sind Conversions oberhalb von `r iqr(Conversions ~ Werbekanal, data = data.conversions)["ADSENSE"] * 1.5 + quantile(Conversions ~ Werbekanal, data = data.conversions, probs = 0.75)["75%"][1,1]` und unterhalb von `r iqr(Conversions ~ Werbekanal, data = data.conversions)["ADSENSE"] * -1.5 + quantile(Conversions ~ Werbekanal, data = data.conversions, probs = 0.25)["25%"][1,1]` als Ausreißer zu deklarieren. Solche Ausreißer haben einen negativen Einfluss auf statistische Analysen, da sie die Ergebnisse in vielerlei Hinsicht verzerren und sich somit auch die Fehlerwahrscheinlichkeit erhöht. 
e. Ein statististisch signfikanter Unterschied bzw. Zusammenhang kann nur dann auch kausaler Natur sein, wenn für mögliche Störvariablen kontrolliert wurde. In diesem Zusammenhang erkannt man zwar, dass die Conversions bei Facebook durchschnittlich höher waren, als bei Google AdSense, allerdings ist völlig unklar, wie viele Personen auf die Werbeanzeigen jeweils insgesamt geklickt haben und dann nicht gekauft haben. So könnten die höheren Conversions bei Facebook auch dadurch begründet sein, dass insgesamt mehr Personen insgesamt auf die Werbeanzeigen geklickt haben als bei Google AdSense. Würde man für diese Störvariable kontrollieren, so würde sich auch die Analyse insgesamt verbessern.

**Aufgabe 5**

a. Die Variable *Absatzmenge in Stückeinheiten* besitzt metrisch-diskretes Skalenniveau, da zwischen zwei beliebigen Werten eine zählbare Anzahl von Werten liegen. Demnach ist zur Visualisierung ein Balkendiagramm besser geeignet, als ein Histogramm.
b. In den vergangenen 5 Jahren lag der absatzmengenbezogene Schwerpunkt zwischen etwa 30.000 und 70.000 Stück pro Tag. Mit größerwerdenden Stückzahlen ist eine Abnahme der Häufigkeit erkennbar, womit es sich um eine rechtschiefe Verteilung handelt. Bezogen auf die Modalität gibt es keine deutlichen Abgrenzungen zwischen zwei oder mehreren Sptizen, weswegen hier von einer unimodalen Verteilung gesprochen werden kann.
c. Bei rechtsschiefen Verteilungen liegt der Mittelwert rechts von Median, da der Mittelwert aufgrund seiner Anfälligkeit gegenüber Ausreißern in Richtung der hier rechts liegenden hohen Ausreißer verzerrt und verschoben wird. 
d. Das Quantile-Quantile-Diagramm trägt die Quantile zweier Variablen gegeneinander ab, um ihre Verteilungen zu vergleichen. Im diesem Falle werden die theoretischen Quantile der Standardnormalverteilung mit den empirischen und standardisierten Quantilen der *Absatzmengen*-Variable verglichen. Läge eine (Standard-)Normalverteilung vor, müssten die Quantile beider Verteilungen an annäherend gleicher Stelle liegen, was im obrigen Diagramm durch die gestrichelte Linie gekennzeichnet ist. Hier ist aber erkennbar, dass es davon starke Abweichungen gibt, was wiederum kennzeichnet, dass hier nicht-normalverteilte Daten vorliegen.
e. Die Urliste lässt sich z.B. durch eine geeignete Funktion wie z.B. die Wurzel- oder Logarithmusfunktion so transformieren, dass die daraus resultierende Verteilung annäherend einer Normalverteilung folgt. Da eine Vielzahl statistischer Methoden mit dem Mittelwert und der Varianz rechnen und diese beiden Maße gegenüber Ausreißern anfällig sind, tendieren diese bei schiefen Daten zu hohen Fehlern. Mithilfe der Variablentransformation lassen sich die Daten ohne Informationsverlust vorher in eine symmetrische Verteilung drücken, wodurch die Lage von Mittelwert und Median annähernd identischt ist.

**Aufgabe 6**

a. Der Durchschnittsbürger würde 50 EUR bezahlen, da der geschätzte Mittelwert in der Population $\mu = 50$ beträgt. Weil es sich hierbei um eine Normalverteilung und somit um eine symmetrische Verteilung handelt, ist der Mittelwert annäherend identisch zum Median. Somit würde auch der typische Bürger 50 EUR für das neue Produkt bezahlen.
b. Gemäß der 68-95-99,7%-Regel liegen die mittleren 95% der Daten zwischen $\mu \pm 2\sigma$. Somit bewegt sich die Preisspanne zwischen 40 und 60 EUR. 95% der Bürger sind somit bereit einen Preis zwischen 40 und 60 EUR zu bezahlen.
c. Gemäß der 68-95-99,7%-Regel liegen die mittleren 97.7% der Daten zwischen $\mu \pm 3\sigma$. Somit muss bei $-3\sigma$ das 0.15%-Quantil liegen, womit die unteren 0.15% der Menschen bereit sind, einen Betrag von 35 EUR oder weniger zu bezahlen. Da die mittleren 95% der Daten zwischen $\mu \pm 2\sigma$ liegen, muss bei $2\sigma$ das 97.5%-Quantil liegen. Daher sind die oberen 2.5% der Menschen bereit einen Betrag von 60 EUR oder höher zu bezahlen.
d. Ein Betrag von 65 EUR ist $3\sigma$ von $\mu$ entfernt. Gemäß der 68-95-99,7%-Regel liegen die mittleren 97.7% der Daten zwischen $\mu \pm 3\sigma$. Somit muss bei $3\sigma$ das 99.85%-Quantil liegen. Entsprechend würden nur $100-99.85=0.15\%$ der Menschen einen Betrag oberhalb von 65 EUR bezahlen. Ein Betrag von 40 EUR ist $-2\sigma$ von $\mu$ entfernt. Da die mittleren 95% der Daten zwischen $\mu \pm 2\sigma$ liegen, muss bei $-2\sigma$ das 2.5%-Quantil liegen. Daher sind die unteren 2.5% der Menschen bereit einen Betrag von maximal 40 EUR zu bezahlen.

**Aufgabe 7**

a) Gemäß der gegebenen Quantilstabelle gilt: $F^{-1}(0.01) = `r data.returns.quantiles[["1%"]]`$. Die Wahrscheinlichkeit, dass Portfolio A am nächsten Tag eine Rendite kleiner oder gleich `r data.returns.quantiles[["1%"]]` (`r round(data.returns.quantiles[["1%"]] * 100, 2)`%) erzielt beträgt 1%. Bei einer Investition in Höhe von 50.000 EUR ergibt sich somit ein potenzieller Verlust von $-50000 \cdot `r data.returns.quantiles[["1%"]]` = `r round(abs(data.returns.quantiles[["1%"]] * 50000), 2)`$ EUR, der mit einer Wahrscheinlichkeit von 99% innerhalb eines Tages nicht überschritten wird.
b) Gemäß der gegebenen Quantilstabelle gilt: $F^{-1}(0.05) = `r data.returns.quantiles[["5%"]]`$. Außerdem ist nun noch der zulässige maximale Verlust in Höhe von 3.000 EUR bekannt, der mit einer Wahrscheinlichkeit von 95% nicht überschritten werden darf. Demnach gilt also analog zu Aufgabenteil b): $\text{ANLAGE} \cdot `r data.returns.quantiles[["5%"]]` = 3000 \Rightarrow \text{ANLAGE} = \frac{3000}{`r data.returns.quantiles[["5%"]]`} = `r round(3000/data.returns.quantiles[["5%"]], 2)`$ EUR. Bei einer Investition von $`r round(abs(3000/data.returns.quantiles[["5%"]]), 2)`$ EUR wird mit einer Wahrscheinlichkeit von 95% ein Verlust in Höhe von 3000 EUR nicht überschritten.
c) Der $z$-Wert von Portfolio A beträgt $\frac{0.035-0.02}{0.015}=1$ und von Portfolio B $\frac{0.04-0.03}{0.02}=0.5$. Da Portfolio A eine halbe Standardabweichung weiter vom Mittelwert entfernt ist als Portfolio B, hat Portfolio A statistisch gesehen besser abgeschnitten.

**Aufgabe 8**

a. In nur $`r (500 - 34)/500` = `r ((500 - 34)/500) * 100`$% der Fälle sind Bestellungen innerhalb von 7 Tagen zugestellt worden. Wenngleich dies erstmal gegen die Einhaltung des SLAs seitens des Lieferanten spricht, erlaubt eine rein deskriptive Betrachtung keinerlei Rückschlüsse auf die Population. Es muss mit einem statistischen Signifikanztest überprüft werden, ob dieses Stichprobenergebnis ungewöhnlich ist und ausreichend stark gegen die Behauptung des Lieferanten spricht.
b. Es gilt $H_0: \pi \ge 0.95$ und $H_A: \pi < 0.95$. Entsprechend handelt es sich bei dem Test um einen gerichteten linkseitigen Hypothesentest. Gemäß der gegebenen Quantile liegt die Stichprobenstatistik $`r (500 - 34)/500`$ zwischen dem 2.5%- und dem 5%-Quantil der Nullverteilung. Da es sich um einen gerichteten linksseitigen Test handelt, würde die Nullhypothese (bei $\alpha = 0.05$) also verworfen werden, wenn das Stichprobenergebnis im Ablehnungsbereich unterhalb des 5%-Quantils liegt, was hier der Fall ist. Demnach ist die Nullhypothese abzulehnen.
c. Der Hypothesentest zeigt mit einer statistischen Signifikanz zu einem Niveau von 5%, dass unter der $H_0$ ein Stichprobenergebnis von $`r (500 - 34)/500`$ extrem ungewöhnlich ist, weswegen die geschlussfolgert werden kann, dass der Lieferant das SLA nicht einhält.
d. Die Nullhypothese wird verworfen, wenn $p < \alpha$. Auch wenn $p$ unbekannt ist, ergibt sich aus der Logik, dass über die Quantile die Nullhypothese abgelehnt werden konnte, der Schluss, dass auch entsprechend $p < \alpha$ sein muss.

**Aufgabe 9**

a. Grundsätzlich kann jede Zufallsstichprobe ungünstig ausfallen. In diesem Zusammenhang könnten also die 250 zufällig ausgewählten Flaschen eben jene sein, die rein zufällig auch eine größere Füllmenge hatte. Es ist daher wichtig, sich nicht nur auf die empirischen Beobachtungen zu verlassen, sondern mittels geeigneter Signifikanztests auch zu überprüfen, ob ein solches Stichprobenergebnis ungewöhnlich ist oder noch im Rahmen des zu erwartbaren gehören.
b. $H_0: \mu = 1000$ und $H_A: \mu \neq 1000$.
c. Bei diesem Hypothesentest handelt es sich um einen ungerichteten zweiseitigen Hypothesentest. Gemäß der gegebenen Quantile liegt die Stichprobenstatistik zwischen dem 95%- und dem 97.5%-Quantil der Nullverteilung. Da es sich um einen ungerichteten Test handelt, würde die Nullhypothese (bei $\alpha = 0.05$) also verworfen werden, wenn das Stichprobenergebnis im Ablehnungsbereich oberhalb des 97.5%-Quantils liegt, was hier nicht der Fall ist. Demnach kann die Nullhypothese nicht abgelehnt werden, da die Stichprobe nicht ausreichend gegen die garantierte durchschnittliche Füllmenge des Herstellers spricht. Es scheint keinen Unterschied zu geben.
d. Da hier zweitseitig bzw. ungerichtet getestet wurde, kann auch nicht gezeigt werden, dass die Füllmenge statistisch signifikant von $H_0$ nach oben oder nach unten abweicht. Dazu bedarf es einem einseitigen Hypothesentest.
e. In diesem nun gerichteten rechtseitigem Test beginnt der Ablehnungsbereich bereits beim 95%-Quantil. Da das Stichprobenergebnis über diesem Quantil liegt, würde die entsprechende Nullhypothese (im Gegensatz zum ungerichteten Test) verworfen werden. Obwohl sich weder die Daten noch die Nullverteilung geändert hat, lehnt man bei dieser Art des Tests die Nullhypothese ab und postuliert somit, dass einen Unterschied gäbe, obwohl im vorherigen Test nicht sicher gezeigt werden konnte, dass es einen gibt. Die Nullhypothesen gerichteter Tests sind daher tendziell eher abzulehnen, weswegen es entsprechend nicht reicht, ein solche Hypothese nur auf Basis der Daten zu stützen, sondern es Bedarf darüber hinaus noch einen validen Erklärungsansatz, der sich möglicherweise auf wissenschaftliche Forschungs stützt.

**Aufgabe 10**

a. $H_0: \mu \ge$ und $H_A: \mu \lt 5$. Da es sich um einen linksseitigen Test auf Basis einer Bootstrap-Simulation handelt, würde die $H_0$ dann verworfen werden, wenn Sie außerhalb des 95%-Konfidenzintervalls zwischen $`r data.macces.quantiles['0%']` \, (0\%)$ und $`r  data.macces.quantiles['95%']` \, (95\%)$ liegt. Die $H_0$ liegt somit außerhalb des 95%-Konfidenzintervalls, weswegen sie abgelehnt werden kann. Mehr als 95% der Simulationen hatten eine durchschnittliche Wartzeit unterhalb von 5 Minuten. Entsprechend ist $H_0$ unter dieser Verteilung unwahrscheinlich.
b. Nein, das Ergebnis ist nicht generalisierar, da 10 von 500 Filialen kaum repräsentativ sein können. Darüber hinaus haben alle zum gleichen Zeitpunkt bestellt. Dies berücksichtigt nicht, dass z.B. wochentags- und zeitbedingt mehr los ist, als sonst. Die Frage ist ja, ob die garantierte Wartezeit im Allgemeinen durchschnittlich eingehalten wird und nicht, ob es auch mal einzelne Fälle gibt, wo man länger warten muss. 

**Aufgabe 11**

a. $H_0: \mu_N \le \mu_A \Rightarrow  \mu_N - \mu_A \le 0$ und $H_A: \mu_N \gt \mu_A \Rightarrow  \mu_N - \mu_A \gt 0$. Da es sich um einen rechtsseitigen Test auf Basis einer Bootstrap-Simulation handelt, würde die $H_0$ dann verworfen werden, wenn Sie außerhalb des 95%-Konfidenzintervalls zwischen $`r data.packaging.bootstrap.quantiles['5%']` \, (5\%)$ und $`r  data.packaging.bootstrap.quantiles['100%']` \, (100\%)$ liegt. Die $H_0$ liegt somit innerhalb des 95%-Konfidenzintervalls, weswegen sie nicht abgelehnt werden kann. Die Daten sprechend nicht ausreichend dafür, dass das neue Produktdesign einen positiven Einfluss auf die Absatzmengen hat.
b. Ursachen könnten sowohl der Stichprobenumfang als auch die Streuung innerhalb der Stichprobe sein. Sowohl bei großer Stichprobenstreuung als auch bei geringem Stichprobenumfang erhöht sich c.p. der Standardfehler. Je größer der Standardfehler, desto größer ist auch entsprechend das 95%-Konfidenzintervall und umso schwieriger ist es, die Nullhypothese abzulehnen.
c. Hierbei würde es sich um einen Fehler 1. Art handeln - dem sogenannten $\alpha$-Fehler. Die Wahrscheinlichkeit eine Nullhypothese irrtümlicherweise abzulehnen, obwohl sie in der Realität gilt, wird durch das Signifikanzniveau selbstständig festgelegt. Wählt man also statt $\alpha=0.05$ ein $\alpha=0.01$, so reduziert sich die Fehlerwahrscheinlichkeit auf einen Prozent.
d. Zwar wurde hier die unabängige Variable (Produktdesign) manipuliert, jedoch nicht für Störvariablen kontrolliert. Dies wird insbesondere daran deutlich, dass der A/B-Test nur in einem Supermarkt durchgeführt wurde. Hätte man in mehreren repräsentativen Supermärkten zufällig das neue bzw. das alte Produktdesign im gleichen Zeitraum verkauft, so wäre besser für Störvariablen kontrolliert worden und somit ein kausaler Schluss eher zulässig.

**Aufgabe 12**

a. Gemäß des geschätzen Regressionsmodells und des darin ermittelten $\beta_{MARKT}$-Koeffizienten verändert sich die erwartete Rendite der Aktie um etwa $`r round(data.capm.lm$coef[2], 4)`$ Prozentpunkte, wenn die Rendite des Marktportfolios eine Änderung um einen Prozentpunkt erfährt. Die Aktie bewegt sich sich somit weniger stark als der Gesamtmarkt.
b. $\hat R_{AKTIE} = `r data.capm.lm$coef[1]` + `r data.capm.lm$coef[2]` \cdot 5 = `r predict(lm(stock ~ index, data = data.capm.returns), newdata = data.frame(index=c(5)))`$. Wenn eine Marktendite in Höhe von 5\% realisiert worden wäre, beträge die Rendite der Aktie etwa `r round(predict(lm(stock ~ index, data = data.capm.returns), newdata = data.frame(index=c(5))), 2)`\%.
c. $H_0: \beta_{MARKT} = 0$ und $H_A: \beta_{MARKT} \neq 0$. Da es sich um einen ungerichteten Test auf Basis einer Bootstrap-Simulation handelt, würde die $H_0$ dann verworfen werden, wenn Sie außerhalb des 95%-Konfidenzintervalls zwischen $`r data.capm.bootstrap.quantiles['2.5%']` \, (2.5\%)$ und $`r  data.capm.bootstrap.quantiles['97.5%']` \, (97.5\%)$ liegt. Die Teststatistik $\beta_{MARKT_0} = 0$ liegt somit außerhalb des 95%-Konfidenzintervalls, weswegen dir $H_0$ abgelehnt werden kann. Die Daten sprechen ausreichend dafür, dass der Gesamtmarkt einen signifikanten Einfluss auf die Rendite der Aktie hat.

## Tabellen

### Standardnormalverteilung

```{r diststd, echo = FALSE}
tbl.dist.std <- matrix(pnorm(seq(0, 3.99, by = 0.01)), ncol = 10, byrow = TRUE)
rownames(tbl.dist.std) <- seq(0, 3.9, by = .1)
colnames(tbl.dist.std) <- seq(0, .09, by = .01)
knitr::kable(tbl.dist.std, row.names = TRUE, booktabs = TRUE, escape = FALSE, caption = "Werte der Verteilungsfunktion $\\Phi(z) = P(Z \\le z)$ für $z \\ge 0$. Ablesebeispiel: $\\Phi(1.75) = 0.9599$. Funktionswerte für negative Argumente: $\\Phi(−z) = 1 − \\Phi(z)$. Die $z$-Quantile ergeben sich genau umgekehrt. Beispielsweise ist $\\tilde{z}_{0.975} = 1.96$", digits = 4)
```